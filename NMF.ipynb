{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn.decomposition\n",
    "import sklearn.feature_extraction\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.09686070e+00   4.75751791e-01   6.94660147e-01]\n",
      " [  1.94409500e-06   8.45813280e-01   1.44194643e+00]]\n",
      "\n",
      "[[ 0.32279775  1.01766758]\n",
      " [ 0.64653046  0.7001715 ]\n",
      " [ 0.96883113  0.85673611]\n",
      " [ 1.29088327  0.58274922]\n",
      " [ 1.61418045  0.10173439]\n",
      " [ 1.93796563 -0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# arbitrary 6x3 matrix (constructed from an example at http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html with a random column concatenated)\n",
    "M = np.concatenate((np.array([[1,1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]]),map(lambda x : [x], np.round(np.random.random_sample(6),1)+1)),1)\n",
    "M\n",
    "H = sklearn.decomposition.NMF(n_components=2).fit(M).components_\n",
    "W = sklearn.decomposition.NMF(n_components=2).fit_transform(M)\n",
    "print H\n",
    "print\n",
    "print W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.421   0.407   2.343   7.722]\n",
      " [  8.856   0.957   2.105   7.88 ]\n",
      " [  0.593   2.335   3.139   3.23 ]\n",
      " [ 10.032   0.466   1.51    8.066]\n",
      " [  1.455   4.472   3.368   1.036]\n",
      " [  0.547   1.294   2.509   4.802]\n",
      " [  0.278   2.185   2.713   3.662]\n",
      " [  9.516   0.362   1.385   8.91 ]\n",
      " [ 10.439   0.974   2.46    7.899]\n",
      " [  0.955   1.937   2.043   3.288]\n",
      " [  9.447   0.332   1.315   8.366]\n",
      " [ 10.663   0.817   2.296   7.643]\n",
      " [  0.505   1.58    4.762   3.843]\n",
      " [  1.041   5.203   3.839   1.218]\n",
      " [  0.843   4.794   4.028   0.647]\n",
      " [ 10.037   0.591   1.634   8.088]\n",
      " [  1.174   2.9     2.486   4.455]\n",
      " [ 10.132   0.787   1.935   7.821]\n",
      " [  1.944   4.886   3.992   1.132]\n",
      " [  0.766   3.906   3.798   1.102]]\n",
      "\n",
      "[[ 0.75906768  0.03279275  0.18877991  0.62217605]\n",
      " [ 0.73325427  0.07923717  0.17428865  0.65244395]\n",
      " [ 0.11609589  0.45713982  0.61454471  0.63236044]\n",
      " [ 0.77352845  0.03593144  0.11643022  0.62193784]\n",
      " [ 0.24759895  0.76100516  0.57313627  0.17629726]\n",
      " [ 0.09772855  0.23118967  0.44826498  0.85793879]\n",
      " [ 0.05492085  0.43166207  0.53597218  0.72345378]\n",
      " [ 0.72560586  0.02760291  0.10560783  0.67939767]\n",
      " [ 0.78163033  0.0729292   0.1841949   0.59144535]\n",
      " [ 0.21544454  0.43698019  0.46089341  0.7417609 ]\n",
      " [ 0.74435405  0.02615916  0.10361232  0.65917921]\n",
      " [ 0.79910416  0.06122743  0.17206632  0.57278   ]\n",
      " [ 0.07965189  0.24920789  0.75109366  0.60614299]\n",
      " [ 0.15626978  0.78104869  0.57629174  0.18284015]\n",
      " [ 0.1327329   0.75482981  0.63422079  0.10187211]\n",
      " [ 0.77167441  0.04543784  0.12562678  0.62182949]\n",
      " [ 0.19617001  0.48457668  0.41539918  0.74441003]\n",
      " [ 0.7812613   0.06068423  0.14920456  0.60306402]\n",
      " [ 0.29021514  0.72941933  0.59595619  0.16899359]\n",
      " [ 0.13651868  0.69613836  0.67689029  0.19640155]]\n",
      "\n",
      "\n",
      "[[  0.754   8.25   15.475   0.   ]\n",
      " [  0.936   4.054  22.838   0.   ]\n",
      " [  0.293   6.947  18.041   0.   ]\n",
      " [  1.723   5.751  13.085   0.   ]\n",
      " [  0.191   8.651  21.912   0.   ]\n",
      " [  2.188   7.951  17.442   0.   ]\n",
      " [  2.237  14.835   0.667   1.   ]\n",
      " [  1.368  16.98    3.028   1.   ]\n",
      " [  0.863  16.637   1.807   1.   ]\n",
      " [  3.039  16.762   0.      1.   ]\n",
      " [  0.779  14.025   4.65    1.   ]\n",
      " [ 18.326   2.209   5.222   2.   ]\n",
      " [ 17.339   2.853   7.051   2.   ]\n",
      " [ 19.755   1.022   3.238   2.   ]\n",
      " [ 18.872   0.      8.843   2.   ]\n",
      " [ 20.301   3.788   2.054   2.   ]\n",
      " [ 18.702   0.118   6.513   2.   ]\n",
      " [ 20.737   3.386   0.      2.   ]\n",
      " [ 19.741   1.478   3.4     2.   ]\n",
      " [ 19.829   2.548   2.13    2.   ]]\n",
      "[0, 0, 2, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 1, 1, 0, 2, 0, 1, 1]\n",
      "[2, 2, 0, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 0, 2, 1, 1]\n",
      "[[ 0.14744841  0.7882343   2.38372752]]\n",
      "\n",
      "\n",
      "[[  0.448   4.764   8.379   0.   ]\n",
      " [  0.496   2.157  11.302   0.   ]\n",
      " [  0.181   4.058   9.864   0.   ]\n",
      " [  1.159   3.833   8.178   0.   ]\n",
      " [  0.095   4.024   9.549   0.   ]\n",
      " [  1.092   3.927   8.077   0.   ]\n",
      " [  1.15    7.413   0.299   1.   ]\n",
      " [  0.633   7.489   1.24    1.   ]\n",
      " [  0.427   7.693   0.763   1.   ]\n",
      " [  1.362   7.344   0.      1.   ]\n",
      " [  0.433   7.343   2.27    1.   ]\n",
      " [  4.361   0.517   1.198   2.   ]\n",
      " [  4.241   0.692   1.651   2.   ]\n",
      " [  4.499   0.226   0.729   2.   ]\n",
      " [  4.249   0.      1.905   2.   ]\n",
      " [  4.491   0.826   0.459   2.   ]\n",
      " [  4.352   0.025   1.459   2.   ]\n",
      " [  4.593   0.737   0.028   2.   ]\n",
      " [  4.483   0.329   0.761   2.   ]\n",
      " [  4.517   0.571   0.49    2.   ]]\n",
      "[0, 0, 2, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 1, 1, 0, 2, 0, 1, 1]\n",
      "[2, 2, 0, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 0, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# a 20x4 example in which there are explicit types (that are unknown to the algorithm)\n",
    "n = 20\n",
    "types = np.trunc(np.random.random_sample(n)*3)\n",
    "means = [[1,2,3,4],[1,5,4,1],[10,1,2,8]]\n",
    "stddevs = 0.5 * np.ones([3,4])\n",
    "def gen(t):\n",
    "    mean = means[t]\n",
    "    sd = stddevs[t]\n",
    "    sz = len(mean)\n",
    "    return list(np.random.randn(sz) * sd + mean)\n",
    "# generate a data matrix\n",
    "M = np.round(map(gen, map(int, types)),3)\n",
    "\n",
    "M_tfidf = sklearn.feature_extraction.text.TfidfTransformer().fit_transform(M).toarray()\n",
    "print M\n",
    "print\n",
    "print M_tfidf\n",
    "print\n",
    "print\n",
    "\n",
    "# run NMF\n",
    "fit = sklearn.decomposition.NMF(n_components=3).fit(M)\n",
    "H = fit.components_\n",
    "W = fit.transform(M)\n",
    "#print H\n",
    "results = list(np.concatenate((10*W,map(lambda x:[x],types)), 1))\n",
    "results.sort(key = lambda row : row[3])\n",
    "results = np.array(map(lambda row : list(np.round(row,3)), results))\n",
    "print results\n",
    "#print map(lambda row : np.argmax(np.round(list(row[0:3]),3)), results)\n",
    "# predicted clusters\n",
    "print map(lambda row : np.argmax(np.round(list(row[0:3]),3)), W)\n",
    "# true clusters\n",
    "print map(int, types)\n",
    "# use fit from above to classify a new point\n",
    "print fit.transform([[1,2,4,5]])\n",
    "\n",
    "print\n",
    "print\n",
    "\n",
    "fit = sklearn.decomposition.NMF(n_components=3).fit(M_tfidf)\n",
    "H = fit.components_\n",
    "W = fit.transform(M_tfidf)\n",
    "#print H\n",
    "results = list(np.concatenate((10*W,map(lambda x:[x],types)), 1))\n",
    "results.sort(key = lambda row : row[3])\n",
    "results = np.array(map(lambda row : list(np.round(row,3)), results))\n",
    "print results\n",
    "#print map(lambda row : np.argmax(np.round(list(row[0:3]),3)), results)\n",
    "# predicted clusters\n",
    "print map(lambda row : np.argmax(np.round(list(row[0:3]),3)), W)\n",
    "# true clusters\n",
    "print map(int, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read in data from csv\n",
    "noun_train_mat = np.loadtxt(\"noun_train_mat.csv\", delimiter = \",\")\n",
    "# use TF-IDF to scale each document's vector to have norm 1 and place a lower weight on very common words\n",
    "tf_idf_fit = sklearn.feature_extraction.text.TfidfTransformer().fit(noun_train_mat)\n",
    "noun_train_mat = tf_idf_fit.transform(noun_train_mat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhu\\Anaconda\\lib\\site-packages\\sklearn\\decomposition\\nmf.py:532: UserWarning: Iteration limit reached during fit. Solving for W exactly.\n",
      "  warnings.warn(\"Iteration limit reached during fit. Solving for W exactly.\")\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute NMF fit\n",
    "NMF_fit = sklearn.decomposition.NMF(n_components=14).fit(noun_train_mat)\n",
    "H = NMF_fit.components_\n",
    "W = NMF_fit.transform(noun_train_mat)\n",
    "# contains a tuple (i,j) if document i is in cluster j, for each document\n",
    "clusters = map(np.argmax, W)\n",
    "# list of the documents in each cluster\n",
    "cluster_lists = [[i for i,j in enumerate(clusters) if j==cluster] for cluster in range(14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per category: [97, 185, 73, 59, 68, 146, 41, 68, 88, 55, 35, 12, 26, 157]\n"
     ]
    }
   ],
   "source": [
    "# classify each document into the category that fits it best\n",
    "print 'Number of documents per category:', [sum([x[1]==i for x in enumerate(clusters)]) for i in range(14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load vocab from csv\n",
    "noun_vocab = np.loadtxt(\"noun_vocab.csv\", delimiter=\",\", dtype=\"str\")\n",
    "noun_vocab = [(int(i),j) for i,j in noun_vocab]\n",
    "id2noun = dict(noun_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['appeal', 'court', 'district', 'petitioner', 'habea'],\n",
       " ['action', 'act', 'respondent', 'court', 'title'],\n",
       " ['union', 'labor', 'employee', 'board', 'employer'],\n",
       " ['search', 'warrant', 'police', 'officer', 'petitioner'],\n",
       " ['tax', 'income', 'revenue', 'property', 'busines'],\n",
       " ['jury', 'trial', 'sentence', 'defendant', 'offense'],\n",
       " ['carrier', 'railroad', 'icc', 'rate', 'commerce'],\n",
       " ['attorney', 'alien', 'brief', 'general', 'cause'],\n",
       " ['commission', 'act', 'price', 'sale', 'company'],\n",
       " ['contract', 'government', 'arbitration', 'agreement', 'contractor'],\n",
       " ['student', 'school', 'plan', 'board', 'education'],\n",
       " ['patent', 'art', 'invention', 'claim', 'royalty'],\n",
       " ['decree', 'orig ', 'master', 'entry', 'boundary'],\n",
       " ['court', 'law', 'statute', 'state', 'amendment']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the 5 most important words for each category\n",
    "num_best = 5\n",
    "best_indices = map(lambda v : list(bn.argpartsort(-v,num_best)[0:num_best]), H)\n",
    "best_words = [[id2noun[i] for i in lst] for lst in best_indices]\n",
    "best_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in SC Database's issue areas from csv\n",
    "noun_train_issue_areas = np.loadtxt(\"noun_train_issue_areas.csv\", delimiter = \",\", dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7, 6, 0, 7, 0, 7, 1, 7, 7, 1, 7, 10, 2]\n",
      "[8, 7, 6, 0, 7, 0, 7, 1, 7, 7, 1, 7, 10, 2]\n",
      "[3, 10, 13, 13, 13, 7, 2, 11, 0, 12, 12, 4, 4, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.26804124,  0.16494845,  0.06185567,  0.03092784,  0.        ,\n",
       "         0.        ,  0.01030928,  0.06185567,  0.36082474,  0.03092784,\n",
       "         0.        ,  0.01030928,  0.        ,  0.        ]),\n",
       " array([ 0.03783784,  0.27567568,  0.05405405,  0.04324324,  0.01621622,\n",
       "         0.        ,  0.01621622,  0.36756757,  0.15675676,  0.02702703,\n",
       "         0.        ,  0.00540541,  0.        ,  0.        ]),\n",
       " array([ 0.01369863,  0.01369863,  0.09589041,  0.01369863,  0.01369863,\n",
       "         0.        ,  0.61643836,  0.04109589,  0.08219178,  0.10958904,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([ 0.89830508,  0.05084746,  0.        ,  0.01694915,  0.01694915,\n",
       "         0.        ,  0.        ,  0.        ,  0.01694915,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([ 0.13235294,  0.04411765,  0.        ,  0.        ,  0.        ,\n",
       "         0.01470588,  0.        ,  0.38235294,  0.04411765,  0.02941176,\n",
       "         0.        ,  0.33823529,  0.01470588,  0.        ]),\n",
       " array([ 0.7260274 ,  0.12328767,  0.04109589,  0.03424658,  0.00684932,\n",
       "         0.        ,  0.        ,  0.04109589,  0.02739726,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([ 0.        ,  0.04878049,  0.        ,  0.04878049,  0.        ,\n",
       "         0.        ,  0.04878049,  0.65853659,  0.14634146,  0.04878049,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([ 0.23529412,  0.33823529,  0.04411765,  0.04411765,  0.01470588,\n",
       "         0.07352941,  0.01470588,  0.07352941,  0.13235294,  0.02941176,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([ 0.03409091,  0.01136364,  0.06818182,  0.01136364,  0.        ,\n",
       "         0.        ,  0.06818182,  0.61363636,  0.09090909,  0.07954545,\n",
       "         0.        ,  0.02272727,  0.        ,  0.        ]),\n",
       " array([ 0.05454545,  0.12727273,  0.03636364,  0.03636364,  0.        ,\n",
       "         0.        ,  0.09090909,  0.45454545,  0.05454545,  0.12727273,\n",
       "         0.        ,  0.01818182,  0.        ,  0.        ]),\n",
       " array([ 0.05714286,  0.57142857,  0.28571429,  0.02857143,  0.        ,\n",
       "         0.        ,  0.02857143,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.02857143,  0.        ,  0.        ]),\n",
       " array([ 0.08333333,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.66666667,  0.08333333,  0.16666667,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([ 0.03846154,  0.07692308,  0.        ,  0.03846154,  0.        ,\n",
       "         0.        ,  0.        ,  0.07692308,  0.07692308,  0.30769231,\n",
       "         0.38461538,  0.        ,  0.        ,  0.        ]),\n",
       " array([ 0.06369427,  0.2611465 ,  0.29299363,  0.05095541,  0.01910828,\n",
       "         0.01273885,  0.        ,  0.07643312,  0.15286624,  0.06369427,\n",
       "         0.        ,  0.00636943,  0.        ,  0.        ])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_mat = map(lambda r : map(int, r), np.zeros((14,14)))\n",
    "for i,j in zip(clusters, noun_train_issue_areas - 1):\n",
    "    compare_mat[i][j] += 1\n",
    "compare_mat = map(lambda row : map(float,row) / sum(row), np.array(compare_mat))\n",
    "\n",
    "assignments = -1 * np.ones(14)\n",
    "compare_mat_flat = [x for lst in compare_mat for x in lst]\n",
    "while min(assignments) == -1:\n",
    "    max_ind = np.argmax(compare_mat_flat)\n",
    "    row = max_ind / 14\n",
    "    if assignments[row] == -1:\n",
    "        column = max_ind - 14 * row\n",
    "        assignments[row] = column\n",
    "    else:\n",
    "        compare_mat_flat[max_ind] = -1\n",
    "#5 / 2\n",
    "print map(int, assignments)\n",
    "print map(np.argmax, compare_mat)\n",
    "print map(np.argmax, np.array(compare_mat).T)\n",
    "\n",
    "compare_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['narcotic', 'fdca', 'middleman', 'narcotic', 'city the', 'middleman', 'city the', 'middleman', 'fdca', 'narcotic', 'city the', 'fdca', 'city the', 'city the']\n"
     ]
    }
   ],
   "source": [
    "# can probably ignore this stuff -- it's a different way to figure out the best words in each category, but it's not working\n",
    "# and produces nonsense\n",
    "width = len(M[0])\n",
    "best_words = np.zeros(14)\n",
    "for i in range(14):\n",
    "    # arbitrary high initial value\n",
    "    w = np.ones(width) * 5000\n",
    "    #w_val = np.ones(width)\n",
    "    for j in range(width):\n",
    "        for k in range(14):\n",
    "            if i <> k and H[k][j] > 0:\n",
    "                if w[j] >= float(H[i][j])/H[k][j]:\n",
    "                    w[j] = float(H[i][j])/H[k][j]\n",
    "    best_words[i] = np.argmax(w)\n",
    "print map(lambda x : id2noun[int(x)], best_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read in test data from csv\n",
    "noun_test_mat = np.loadtxt(\"noun_test_mat.csv\", delimiter = \",\")\n",
    "# use TF-IDF to scale each document's vector to have norm 1 and place a lower weight on very common words\n",
    "noun_test_mat = tf_idf_fit.transform(noun_test_mat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use NMF fit from training data to cluster test observations\n",
    "W_test = NMF_fit.transform(noun_test_mat)\n",
    "clusters_test = map(np.argmax, W_test)\n",
    "cluster_lists_test = [[i for i,j in enumerate(clusters_test) if j==cluster] for cluster in range(14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21, 32, 40, 41, 68, 76, 88, 91, 97, 98, 100, 101, 102, 107, 110, 130, 175, 205, 221, 224, 225, 226, 227, 254, 270, 271, 273, 288, 289, 312, 321, 324, 327, 335, 340, 364, 369, 381, 383, 391, 404, 423, 446, 457, 459], [3, 10, 13, 24, 30, 43, 48, 50, 75, 77, 80, 92, 104, 108, 112, 116, 135, 136, 139, 145, 152, 154, 165, 169, 179, 210, 233, 239, 242, 245, 246, 247, 264, 266, 267, 275, 276, 279, 295, 301, 305, 314, 315, 318, 320, 334, 337, 338, 343, 344, 345, 360, 371, 372, 374, 375, 378, 386, 387, 390, 394, 401, 403, 408, 409, 428, 431, 451, 458, 465, 470, 471, 473, 480, 481, 482, 484], [12, 19, 26, 59, 62, 64, 103, 120, 144, 149, 180, 182, 193, 194, 199, 240, 265, 272, 291, 304, 307, 309, 313, 319, 380, 389, 454, 460, 461, 467, 476], [22, 36, 54, 122, 132, 160, 162, 219, 228, 241, 244, 310, 347, 356, 368, 405, 407, 412, 424, 432, 453, 472], [6, 11, 23, 25, 33, 35, 38, 58, 83, 114, 115, 118, 119, 126, 129, 147, 148, 150, 166, 191, 197, 209, 211, 232, 252, 253, 269, 285, 290, 303, 339, 379, 402, 413, 443, 462, 474, 479, 483], [5, 28, 34, 51, 52, 53, 55, 56, 65, 71, 78, 79, 84, 90, 113, 124, 140, 143, 146, 159, 167, 171, 174, 176, 183, 187, 202, 203, 204, 206, 213, 216, 218, 230, 234, 236, 248, 258, 261, 262, 268, 277, 282, 292, 297, 298, 299, 317, 325, 332, 341, 361, 362, 366, 370, 399, 406, 410, 411, 422, 425, 435, 438, 444, 448, 450, 464, 466, 468, 478], [14, 39, 60, 61, 63, 67, 87, 121, 127, 178, 208, 260, 263, 363, 455], [0, 20, 37, 42, 57, 125, 151, 161, 173, 177, 181, 189, 220, 231, 235, 237, 249, 329, 346, 350, 354, 359, 365, 376, 416, 419, 429, 440, 452], [8, 29, 66, 73, 74, 81, 94, 105, 117, 123, 131, 155, 156, 164, 185, 195, 196, 207, 214, 223, 251, 255, 283, 287, 311, 322, 326, 342, 348, 352, 367, 373, 385, 398, 433, 434, 441, 456, 469, 475], [15, 31, 44, 47, 106, 128, 133, 138, 257, 274, 284, 286, 296, 306, 316, 331, 351, 353, 400, 421, 449, 463], [1, 72, 153, 172, 217, 333, 395, 417, 427, 430], [9, 46, 82, 95, 142, 188, 293, 414, 420, 445], [27, 111, 157, 163, 170, 192, 198, 201, 294, 300, 349, 355, 382, 392], [2, 4, 7, 16, 17, 18, 45, 49, 69, 70, 85, 86, 89, 93, 96, 99, 109, 134, 137, 141, 158, 168, 184, 186, 190, 200, 212, 215, 222, 229, 238, 243, 250, 256, 259, 278, 280, 281, 302, 308, 323, 328, 330, 336, 357, 358, 377, 384, 388, 393, 396, 397, 415, 418, 426, 436, 437, 439, 442, 447, 477]]\n"
     ]
    }
   ],
   "source": [
    "print cluster_lists_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
