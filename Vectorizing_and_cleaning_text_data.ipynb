{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vectorizing and cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option(\"display.width\", 500)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.notebook_repr_html\", True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get dataframe of some opinions from csv \n",
    "opinion_df = pd.read_table(\"raw_clistener_data.csv\",nrows=45000)\n",
    "\n",
    "#dftouse=pd.read_csv(\"dftouse.csv\")\n",
    "#dftouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>blocked</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1922-05-29</td>\n",
       "      <td>100000</td>\n",
       "      <td>Morrisdale Coal Co. v. United States</td>\n",
       "      <td>259 U.S. 188 (1922)MORRISDALE COAL COMPANYv.UN...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1922-05-29</td>\n",
       "      <td>100001</td>\n",
       "      <td>Pine Hill Coal Co. v. United States</td>\n",
       "      <td>259 U.S. 191 (1922)PINE HILL COAL COMPANY, INC...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1922-05-29</td>\n",
       "      <td>100002</td>\n",
       "      <td>Santa Fe Pacific R. Co. v. Fall</td>\n",
       "      <td>259 U.S. 197 (1922)SANTA FE PACIFIC RAILROAD C...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1922-05-29</td>\n",
       "      <td>100003</td>\n",
       "      <td>Federal Baseball Club of Baltimore, Inc. v. Na...</td>\n",
       "      <td>259 U.S. 200 (1922)FEDERAL BASEBALL CLUB OF BA...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>1922-05-29</td>\n",
       "      <td>100004</td>\n",
       "      <td>Mutual Life Ins. Co. of NY v. Liebing</td>\n",
       "      <td>259 U.S. 209 (1922)MUTUAL LIFE INSURANCE COMPA...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 blocked        date      id                                               name                                               text  url\n",
       "0          0   False  1922-05-29  100000               Morrisdale Coal Co. v. United States  259 U.S. 188 (1922)MORRISDALE COAL COMPANYv.UN...  NaN\n",
       "1          1   False  1922-05-29  100001                Pine Hill Coal Co. v. United States  259 U.S. 191 (1922)PINE HILL COAL COMPANY, INC...  NaN\n",
       "2          2   False  1922-05-29  100002                    Santa Fe Pacific R. Co. v. Fall  259 U.S. 197 (1922)SANTA FE PACIFIC RAILROAD C...  NaN\n",
       "3          3   False  1922-05-29  100003  Federal Baseball Club of Baltimore, Inc. v. Na...  259 U.S. 200 (1922)FEDERAL BASEBALL CLUB OF BA...  NaN\n",
       "4          4   False  1922-05-29  100004              Mutual Life Ins. Co. of NY v. Liebing  259 U.S. 209 (1922)MUTUAL LIFE INSURANCE COMPA...  NaN"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Code for parsing, cleaning, vectorizing\n",
    "Below, I take three cases as a small sample on which to write code that parses, cleans and vectorizes the text\n",
    "\n",
    "The python pattern module is useful: http://www.clips.ua.ac.be/pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get sample cases, and put them in list\n",
    "op1 = opinion_df.iloc[1]['text']\n",
    "op2 = opinion_df.iloc[2]['text']\n",
    "op3 = opinion_df.iloc[3]['text']\n",
    "opsdict = {'op1':[op1],'op2':[op2],'op3':[op3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We create regular expressions [MAYBE USE LATER SOMEHOW]\n",
    "import re\n",
    "regex1=re.compile(r\"\\.{2,}\")\n",
    "regex2=re.compile(r\"\\-{2,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We only consider the actual opinion. This is what comes after the phrase \"delivered the opinion of the court.\" \n",
    "deliverstring=\"delivered the opinion of the court.\" \n",
    "for key,value in opsdict.iteritems():\n",
    "    oplow = value[0].lower() #make text lowercase\n",
    "    #If opinion includes deliverstring, we use the opinion for analysis\n",
    "    if deliverstring in oplow: \n",
    "        optouse = oplow.split(deliverstring)[1]\n",
    "        opsdict[key].append(optouse)\n",
    "        \n",
    "#GET A LIST OF PRECEDENTS CITED IN THE OPINION \n",
    "for key,value in opsdict.iteritems():\n",
    "    wordslist = value[1].split()\n",
    "    #find precedents based on string 'v.' (eg, 'Brown v. Board')\n",
    "    indices = [i for i in range(len(wordslist)) if wordslist[i]=='v.']\n",
    "    precedents = [wordslist[i-1]+ ' ' + wordslist[i]+ ' ' + wordslist[i+1] for i in indices]\n",
    "    opsdict[key].append(precedents)\n",
    "#note: each opsdict[key] is now a list of [original opinion, optouse, [precedents]]\n",
    "\n",
    "#CLEAN DATA: REMOVE STOPWORDS\n",
    "#we want to get a list of all the nouns and all the adjectives used in each case, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will ultimately be turned into a function like get_parts in HW5. Probably combine with above to also return precedents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.en import conjugate, lemma, lexeme\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "#using this text for writing code\n",
    "testop = opsdict['op2'][1]\n",
    "\n",
    "#get stopwords, punctuation\n",
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')\n",
    "#remove precedents, as we have already accounted for these\n",
    "for precedent in opsdict['op2'][2]:\n",
    "    testop = testop.replace(precedent,'')\n",
    "#parse into list of lists \n",
    "parsed = parse(testop,tokenize=True,chunks=False,lemmata=True).split()\n",
    "verbs = [] \n",
    "nouns = [] \n",
    "adjectives = [] \n",
    "foreign = [] \n",
    "i=0\n",
    "#Create lists of lists of verbs, nouns, adjectives and foreign words in each sentence.\n",
    "for sentence in parsed: #for each sentence \n",
    "    verbs.append([])\n",
    "    nouns.append([])\n",
    "    adjectives.append([])\n",
    "    foreign.append([])\n",
    "    for token in sentence: #for each word in the sentence \n",
    "        if token[0]  in punctuation or token[0] in stopwords or len(token[0])==1:\n",
    "            continue\n",
    "        else:\n",
    "            if token[1] in ['VB','VBZ','VBP','VBD','VBN','VBG']:\n",
    "                verbs[i].append(lemma(token[0])) #append the lemmatized verb (we relemmatize because lemmata in parse does not seem to always work)\n",
    "            if token[1] in ['NN','NNS','NNP','NNPS']:\n",
    "                nouns[i].append(lemma(token[0]))\n",
    "            if token[1] in ['JJ','JJR','JJS']:\n",
    "                adjectives.append(lemma(token[0]))\n",
    "            if token[1] in ['FW']:\n",
    "                foreign.append(token[0])  \n",
    "    i+=1  \n",
    "#Zip together lists so each tuple is a sentence. \n",
    "out=zip(verbs,nouns,adjectives,foreign)\n",
    "verbs2 = []\n",
    "nouns2 = []\n",
    "adjectives2 = []\n",
    "foreign2 = []\n",
    "for sentence in out: \n",
    "    if sentence[0]!=[]&sentence[1]!=0: #if the sentence has at least one verb and noun, keep it. Otherwise, drop it.\n",
    "        verbs2.append(sentence[0])\n",
    "        nouns2.append(sentence[1])\n",
    "        adjectives2.append(sentence[2])\n",
    "        foreign2.append(sentence[3])\n",
    "## return(verbs2,nouns2,adjectives2,foreign2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do next**: \n",
    "Create vocabulary lists\n",
    "Create corpus in bag of words forms\n",
    "\n",
    "**Also to consider**: \n",
    "more data cleaning: (1) can do regex stuff (2) can do ngrams (3) maybe try to look for legal terms (4) more rigorous/complex method for finding precedents. In particular, don't just define the precedent as word before and word after \"v.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
