{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option(\"display.width\", 500)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.notebook_repr_html\", True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF converter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#this function takes a training matrix of size n_documents_training*vocab_size and a test matrix\n",
    "#of size n_documents_test*vocab_size. The function outputs the corresponding tfidf matrices.\n",
    "#Note that we fit on the training data, and then apply that fit to the test data.\n",
    "def tfidf_mat_creator(trainmatrix,testmatrix):\n",
    "    tf_idf_transformer=TfidfTransformer()\n",
    "    tfidf_fit = tf_idf_transformer.fit(trainmatrix)\n",
    "    tfidf_train = tfidf_fit.transform(trainmatrix).toarray()\n",
    "    tfidf_test = tfidf_fit.transform(testmatrix).toarray()\n",
    "    return(tfidf_train,tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE BELOW CELL WILL BE DIFFERENT - NOT THIS EXACT CODE. Basically, you just need to create the noun training and test matrices. Don't convert to TF-IDF yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#GET TRAINING AND TEST MATRICES FOR NOUNS\n",
    "noun_train_df = pd.read_csv('noun_train_mat.csv',sep=',',header=None)\n",
    "noun_train_mat = noun_train_df.values\n",
    "noun_test_df = pd.read_csv('noun_test_mat.csv',sep=',',header=None)\n",
    "noun_test_mat = noun_test_df.values\n",
    "#TRAINING AND TEST MATRICES FOR VERBS\n",
    "verb_train_df = pd.read_csv('verb_train_mat.csv',sep=',',header=None)\n",
    "verb_train_mat = verb_train_df.values\n",
    "verb_test_df = pd.read_csv('verb_test_mat.csv',sep=',',header=None)\n",
    "verb_test_mat = verb_test_df.values\n",
    "#TRAIN AND TEST ISSUE AREAS \n",
    "train_issue_areas_df = pd.read_csv('train_issue_areas.csv',sep=',',header=None)\n",
    "train_issue_areas = train_issue_areas_df.values.ravel()\n",
    "test_issue_areas_df = pd.read_csv('test_issue_areas.csv',sep=',',header=None)\n",
    "test_issue_areas = test_issue_areas_df.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below function will combine verb and noun matrices into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_combine(matrix_list):    \n",
    "    train_mat = np.concatenate(([element[0] for element in matrix_list]),axis=1)\n",
    "    test_mat = np.concatenate(([element[1] for element in matrix_list]),axis=1)\n",
    "    return(train_mat,test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine verb and noun; convert to TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine verb and noun matrices\n",
    "matrix_list = [(verb_train_mat,verb_test_mat),(noun_train_mat,noun_test_mat)]\n",
    "train_verbnouns,test_verbnouns = matrix_combine(matrix_list)\n",
    "#convert the combined matrix to TF-IDF\n",
    "train_verbnouns_tfidf,test_verbnouns_tfidf = tfidf_mat_creator(train_verbnouns,test_verbnouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM-specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "confusion_mat_creator\n",
    "\n",
    "Inputs\n",
    "------\n",
    "predictions: a list of length n_documents. Each value in the list is the predicted\n",
    "             issue area of the corresponding document. (\"Predicted\" as predicted by the SVM.)\n",
    "actuals: a list of length n_documents. Each value is the actual issue area of the corresponding document.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "A 14*14 confusion matrix. Cell i,j is the number of cases with actual issue area j \n",
    "that were predicted as issue area i. Thus, the diagonal represents correct predictions.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "see do_classify below for an example of how this is used\n",
    "\"\"\"\n",
    "\n",
    "def confusion_mat_creator(predictions,actuals): \n",
    "    confusion_mat = np.zeros((14,14))\n",
    "    for i in range(len(predictions)):\n",
    "        #get predicted and actual issue ares; subtract by 1 since matrix is 0-indexed\n",
    "        p_val = predictions[i]-1\n",
    "        a_val = actuals[i]-1\n",
    "        confusion_mat[p_val,a_val]+=1 #Matrix is thus predicted values*actual values \n",
    "    return(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "cv_optimize\n",
    "\n",
    "Inputs\n",
    "------\n",
    "clf : an instance of a scikit-learn classifier\n",
    "parameters: a parameter grid dictionary thats passed to GridSearchCV\n",
    "X: a document-word matrix (e.g., noun_train_tfidf). Should be training data.\n",
    "y: the response vector (train_issue_areas)\n",
    "n_folds: the number of cross-validation folds (default 5)\n",
    "score_func: a score function we might want to pass (default python None)\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "Two things: (1) The best estimator from the GridSearchCV, after the GridSearchCV has been used to\n",
    "fit the model; and (2) the best parameter. \n",
    "     \n",
    "Notes\n",
    "-----\n",
    "see do_classify below for an example of how this is used\n",
    "\"\"\"\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#note: this code comes directly from lab 6\n",
    "def cv_optimize(clf, parameters, X, y, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "    best_estimator = gs.best_estimator_\n",
    "    best_param = gs.best_params_\n",
    "    return (best_estimator,best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "do_classify\n",
    "\n",
    "Inputs\n",
    "------\n",
    "clf : an instance of a scikit-learn classifier\n",
    "parameters: a parameter grid dictionary thats passed to GridSearchCV\n",
    "Xtrain: a training matrix document-word matrix (e.g., noun_train_tfidf)\n",
    "ytrain: the corresponding training response vector (train_issue_areas)\n",
    "Xtest: a test matrix document-word matrix (e.g., noun_test_tfidf)\n",
    "ytest: the corresponding test resonse vector (e.g., noun)\n",
    "n_folds: the number of cross-validation folds (default 5)\n",
    "score_func: a score function we might want to pass (default python None)\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "4 things, in the following order: (1) an array of predicted y values (ie, topic areas) for the test data; \n",
    "                                  (2) the accuracy score; (3) the confusion matrix of the test data predictions;\n",
    "                                  (4) the best parameter from the gridsearch.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "##from sklearn.metrics import confusion_matrix\n",
    "def do_classify(clf, parameters, Xtrain, ytrain, Xtest, ytest, score_func=None, n_folds=5):\n",
    "    if parameters:\n",
    "        clf,best_param = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    print \"Best parameter: \", best_param\n",
    "    pred = clf.predict(Xtest)\n",
    "    print \"########################################################\"\n",
    "    print confusion_mat_creator(pred, ytest)\n",
    "    return(pred,test_accuracy,confusion_mat_creator(pred,ytest),best_param,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run optimized SVM on the tfidf matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_predictions,best_accuracy,best_con_mat,best_param,best_clf=do_classify(LinearSVC(loss='hinge'), {'C':[1.0]},\n",
    "                                                                            train_verbnouns_tfidf,train_issue_areas,\n",
    "                                                                            test_verbnouns_tfidf, test_issue_areas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
