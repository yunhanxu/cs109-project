{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option(\"display.width\", 500)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.notebook_repr_html\", True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TF-IDF term weighting \n",
    "TF-IDF (term-frequency inverse document-frequency) is a method for extracting the usefulness of words and terms. It weights up for term frequency in document, and weights down for the number of documents a term appears in. The formula is:  $$\\text{new_frequency} = tf * (idf + 1)$$\n",
    "$tf = \\text{number of times term appears in document}/\\text{number of words in document}$, $idf = \\text{total number of documents}/\\text{number of documents in which term appears}$\n",
    "\n",
    "See: http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting, http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "\n",
    "The below function takes a bag-of-words matrix (size n_documents\\*vocab_size), and outputs the corresponding tfidf matrix. We show an example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample bag-of-words matrix of 3 documents, vocab size 4 words: \n",
      "[[2 1 0 0]\n",
      " [4 2 1 4]\n",
      " [0 0 0 3]]\n",
      "tfidf transformation of above matrix: \n",
      "[[ 0.89442719  0.4472136   0.          0.        ]\n",
      " [ 0.65121271  0.32560635  0.21406661  0.65121271]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#this function takes a matrix of size n_documents*vocab_size, and outputs the corresponding tfidf matrix \n",
    "def tfidf_mat_creator(wordmatrix):\n",
    "    tf_idf_transform=TfidfTransformer()\n",
    "    return(tf_idf_transform.fit_transform(wordmatrix).toarray())\n",
    "\n",
    "#Example\n",
    "samplematrix = np.random.randint(0, high=5, size=(3,4))\n",
    "print \"Sample bag-of-words matrix of 3 documents, vocab size 4 words: \"\n",
    "print samplematrix\n",
    "print \"tfidf transformation of above matrix: \" \n",
    "print tfidf_mat_creator(samplematrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SVM\n",
    "We try running some SVMs on nouns. \n",
    "\n",
    "First, we must import the noun training and test matrices, and we convert them to tfidf matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GET TRAINING AND TEST MATRICES FOR NOUNS\n",
    "from numpy import genfromtxt\n",
    "##%%time\n",
    "noun_train_df = pd.read_csv('noun_train_mat.csv',sep=',',header=None)\n",
    "noun_train_mat = noun_train_df.values\n",
    "noun_test_df = pd.read_csv('noun_test_mat.csv',sep=',',header=None)\n",
    "noun_test_mat = noun_test_df.values\n",
    "train_issue_areas_df = pd.read_csv('train_issue_areas.csv',sep=',',header=None)\n",
    "train_issue_areas = train_issue_areas_df.values.ravel()\n",
    "test_issue_areas_df = pd.read_csv('test_issue_areas.csv',sep=',',header=None)\n",
    "test_issue_areas = test_issue_areas_df.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert the matrices to tfidf matrices \n",
    "noun_train_tfidf = tfidf_mat_creator(noun_train_mat)\n",
    "noun_test_tfidf = tfidf_mat_creator(noun_test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Simple practice SVM\n",
    "We train and run a simple linear SVM. We follow https://www.quantstart.com/articles/Supervised-Learning-for-Document-Classification-with-Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.5 s, sys: 165 ms, total: 37.6 s\n",
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "def train_svm(X, y):\n",
    "    #this creates and trains the SVM\n",
    "    svm = SVC(C=1000000.0, gamma=0.0, kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm\n",
    "svm1 = train_svm(noun_train_tfidf,train_issue_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm1.dual_coef_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663385826772\n"
     ]
    }
   ],
   "source": [
    "pred = svm1.predict(noun_test_tfidf)\n",
    "#accuracy rate on test set \n",
    "print(svm1.score(noun_test_tfidf, test_issue_areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89 13  3  3  1  1  0  2  6  0  0  0  1]\n",
      " [ 8 63  6  3  1  1  0 14 12  2  1  2  0]\n",
      " [ 0  3 23  0  0  0  0  1  1  0  0  0  0]\n",
      " [ 1  0  0  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 23  0  2  4  0  0  0]\n",
      " [ 2  7  0  5  0  1  2 78 10  7  0  6  0]\n",
      " [ 4 10  6  1  1  0  1  7 36  1  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  2  1  9  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  2  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  9  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(pred, test_issue_areas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Trying multiple SVMs on nouns\n",
    "We now test a variety of parameters and do cross-validation to optimize the nouns SVM. To do this, we implement functions cv_optimize and do_classify, which are similar to (and largely taken from) the equivalently named functions in problem set 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "cv_optimize\n",
    "\n",
    "Inputs\n",
    "------\n",
    "clf : an instance of a scikit-learn classifier\n",
    "parameters: a parameter grid dictionary thats passed to GridSearchCV\n",
    "X: a document-word matrix (e.g., noun_train_tfidf). Should be training data.\n",
    "y: the response vector (train_issue_areas)\n",
    "n_folds: the number of cross-validation folds (default 5)\n",
    "score_func: a score function we might want to pass (default python None)\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "Two things: (1) The best estimator from the GridSearchCV, after the GridSearchCV has been used to\n",
    "fit the model; and (2) the best parameter. \n",
    "     \n",
    "Notes\n",
    "-----\n",
    "see do_classify below for an example of how this is used\n",
    "\"\"\"\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#note: this code comes directly from lab 6\n",
    "def cv_optimize(clf, parameters, X, y, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "    best_estimator = gs.best_estimator_\n",
    "    best_param = gs.best_params_\n",
    "    return (best_estimator,best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "do_classify\n",
    "\n",
    "Inputs\n",
    "------\n",
    "clf : an instance of a scikit-learn classifier\n",
    "parameters: a parameter grid dictionary thats passed to GridSearchCV\n",
    "Xtrain: a training matrix document-word matrix (e.g., noun_train_tfidf)\n",
    "ytrain: the corresponding training response vector (train_issue_areas)\n",
    "Xtest: a test matrix document-word matrix (e.g., noun_test_tfidf)\n",
    "ytest: the corresponding test resonse vector (e.g., noun)\n",
    "n_folds: the number of cross-validation folds (default 5)\n",
    "score_func: a score function we might want to pass (default python None)\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "4 things, in the following order: (1) an array of predicted y values (ie, topic areas) for the test data; \n",
    "                                  (2) the accuracy score; (3) the confusion matrix of the test data predictions;\n",
    "                                  (4) the best parameter from the gridsearch.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def do_classify(clf, parameters, Xtrain, ytrain, Xtest, ytest, score_func=None, n_folds=5):\n",
    "    if parameters:\n",
    "        clf,best_param = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    print \"Best parameter: \", best_param\n",
    "    pred = clf.predict(Xtest)\n",
    "    ##print confusion_matrix(ytest, pred)\n",
    "    print \"########################################################\"\n",
    "    return(pred,test_accuracy,'confusion_matrix_broken',best_param)\n",
    "    ##return(pred,test_accuracy,confusion_matrix(ytest,pred),best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Linear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 5 µs, total: 10 µs\n",
      "Wall time: 12.9 µs\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.96\n",
      "Accuracy on test data:     0.68\n",
      "Best parameter:  {'C': 1.0}\n",
      "[[91  4  1  1  0  0  0  5  2  0  0  0  0]\n",
      " [15 64  2  0  0  0  0  5 11  0  0  0  0]\n",
      " [ 6  4 21  0  0  0  1  2  4  0  0  0  0]\n",
      " [ 4  3  0  2  0  0  1  3  2  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  1  1  0  0  0  0]\n",
      " [ 1  0  0  0  0  2  0  1  1  0  0  1  0]\n",
      " [ 0  0  0  0  0  0 23  2  1  0  0  0  0]\n",
      " [ 6  4  3  0  0  0  1 88  2  0  0  0  0]\n",
      " [ 8  5  1  0  0  0  3 14 37  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  6  9  1  6  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  4  0  0]\n",
      " [ 0  1  0  0  0  0  0  7  0  0  0  9  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Max/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:417: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "#Try do_classify on best 6 parameters\n",
    "%time\n",
    "parameters1 = {\"C\": [0.0001, 0.01, 1.0, 100.0, 1000.0, 100000.0]}\n",
    "predictions1,accuracy1,confusion_matrix1,best_param1=do_classify(LinearSVC(loss='hinge'), parameters1, \n",
    "                                                                 noun_train_tfidf,train_issue_areas,\n",
    "                                                                 noun_test_tfidf,test_issue_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.96\n",
      "Accuracy on test data:     0.68\n",
      "Best parameter:  {'C': 1.0}\n",
      "[[91  4  1  1  0  0  0  5  2  0  0  0  0]\n",
      " [15 64  2  0  0  0  0  5 11  0  0  0  0]\n",
      " [ 6  4 21  0  0  0  1  2  4  0  0  0  0]\n",
      " [ 4  3  0  2  0  0  1  3  2  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  1  1  0  0  0  0]\n",
      " [ 1  0  0  0  0  2  0  1  1  0  0  1  0]\n",
      " [ 0  0  0  0  0  0 23  2  1  0  0  0  0]\n",
      " [ 6  4  3  0  0  0  1 88  2  0  0  0  0]\n",
      " [ 8  5  1  0  0  0  3 14 37  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  6  9  1  6  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  4  0  0]\n",
      " [ 0  1  0  0  0  0  0  7  0  0  0  9  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "#Rerun do_classify based on the best parameter above\n",
    "paramvalue = best_param1.values()[0]\n",
    "parameters2 = {\"C\": [paramvalue/10.,paramvalue,paramvalue*10]}\n",
    "predictions2,accuracy2,confusion_matrix2,best_param2=do_classify(LinearSVC(loss='hinge'), parameters2, \n",
    "                                                             noun_train_tfidf,train_issue_areas,\n",
    "                                                             noun_test_tfidf,test_issue_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Non-linear SVCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell optimizes a kernelized SVM across an array of parameters. Because it takes a long time to run, we only run it once. (We've included an image of the initial output below.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "##%time\n",
    "#parameters grid\n",
    "##parameters3 = {\"C\": [1e-5,1e-3,1,1e3,1e5],\"gamma\":[0,1e-3,1e-5,1e-7]}\n",
    "#test non-linear (kernelized) SVMs\n",
    "##predictions3,accuracy3,confusion_matrix3,best_param3=do_classify(SVC(), parameters3, \n",
    "##                                                             noun_train_tfidf,train_issue_areas,\n",
    "##                                                             noun_test_tfidf,test_issue_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kernelized_svm_output.png\" width=600 height=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further optimize based on the best parameters from the above cell. The result shows that in fact, the best parameters were the ones in the above cell ($C=1e^5$, gamma=$1e^{-5}$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "Accuracy on training data: 1.00\n",
      "Accuracy on test data:     0.68\n",
      "Best parameter:  {'C': 100000.0, 'gamma': 1e-05}\n",
      "[[87  6  1  2  0  0  0  4  4  0  0  0  0]\n",
      " [14 63  2  1  0  0  0  6 10  1  0  0  0]\n",
      " [ 4  8 21  0  0  0  0  1  4  0  0  0  0]\n",
      " [ 3  3  0  3  0  0  0  5  1  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 2  0  0  0  0  2  0  1  0  0  0  1  0]\n",
      " [ 0  1  0  0  0  0 22  2  1  0  0  0  0]\n",
      " [ 3  4  1  0  0  0  1 87  6  2  0  0  0]\n",
      " [ 6  7  1  0  0  0  2 13 39  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  6  7  0  9  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  2  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  9  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "########################################################\n",
      "CPU times: user 11min 8s, sys: 2.84 s, total: 11min 10s\n",
      "Wall time: 11min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#parameters grid\n",
    "parameters4 = {\"C\": [1e4,1e5,1e6,1e7],\"gamma\":[1e-5]}\n",
    "#test non-linear (kernelized) SVMs\n",
    "predictions4,accuracy4,confusion_matrix4,best_param4=do_classify(SVC(), parameters4,\n",
    "                                                                 noun_train_tfidf,train_issue_areas,\n",
    "                                                                 noun_test_tfidf,test_issue_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###SVMs on other types of words\n",
    "So far, we have only tried running SVMs on nouns. We got equally good output (accuracy score = .68) for both the linear SVM and the kernelized SVM, using their respective optimized parameters. However, we may be able to get better ouput by running the SVM on other types of words (eg, verbs, precedents, etc.), or by running it on multiple types of words (e.g., nouns and precedents together). We try some of these things below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#first, we import the different types of words \n",
    "prec_train_df = pd.read_csv('prec_train_mat.csv',sep=',',header=None)\n",
    "prec_train_mat = prec_train_df.values\n",
    "prec_test_df = pd.read_csv('prec_test_mat.csv',sep=',',header=None)\n",
    "prec_test_mat = prec_test_df.values\n",
    "\n",
    "verb_train_df = pd.read_csv('verb_train_mat.csv',sep=',',header=None)\n",
    "verb_train_mat = verb_train_df.values\n",
    "verb_test_df = pd.read_csv('verb_test_mat.csv',sep=',',header=None)\n",
    "verb_test_mat = verb_test_df.values\n",
    "\n",
    "adj_train_df = pd.read_csv('adj_train_mat.csv',sep=',',header=None)\n",
    "adj_train_mat = adj_train_df.values\n",
    "adj_test_df = pd.read_csv('adj_test_mat.csv',sep=',',header=None)\n",
    "adj_test_mat = adj_test_df.values\n",
    "\n",
    "for_train_df = pd.read_csv('for_train_mat.csv',sep=',',header=None)\n",
    "for_train_mat = for_train_df.values\n",
    "for_test_df = pd.read_csv('for_test_mat.csv',sep=',',header=None)\n",
    "for_test_mat = for_test_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function `matrix_combine`, which takes a list of matrix tuples as inputs. Each tuple has two elements, which must be the training and test matrices of the same word type. For example, an input could be: `[(for_train_mat,for_test_mat),(adj_train_mat,adj_test_mat)]`. The function outputs the concatenated test and training matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matrix_combine(matrix_list):    \n",
    "    train_mat = np.concatenate(([element[0] for element in matrix_list]),axis=1)\n",
    "    test_mat = np.concatenate(([element[1] for element in matrix_list]),axis=1)\n",
    "    return(train_mat,test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Linear SVM\n",
    "We try running the linear SVM on each of the four types of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.99\n",
      "Accuracy on test data:     0.29\n",
      "Best parameter:  {'C': 1.0}\n",
      "########################################################\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.89\n",
      "Accuracy on test data:     0.42\n",
      "Best parameter:  {'C': 1.0}\n",
      "########################################################\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.94\n",
      "Accuracy on test data:     0.47\n",
      "Best parameter:  {'C': 1.0}\n",
      "########################################################\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.11\n",
      "Accuracy on test data:     0.09\n",
      "Best parameter:  {'C': 1.0}\n",
      "########################################################\n",
      "verb :  0.474409448819\n",
      "adj :  0.42125984252\n",
      "for :  0.0925196850394\n",
      "prec :  0.28937007874\n"
     ]
    }
   ],
   "source": [
    "#EACH INDIVIDUALLY\n",
    "linear_1_resultsdict= {}\n",
    "#loop through each type of words \n",
    "for matrixpair in [(prec_train_mat,prec_test_mat,'prec'),(adj_train_mat,adj_test_mat,'adj'),\n",
    "                   (verb_train_mat,verb_test_mat,'verb'),(for_train_mat,for_test_mat,'for')]:\n",
    "    #convert to TF-IDF form \n",
    "    train_tfidf = tfidf_mat_creator(matrixpair[0])\n",
    "    test_tfidf = tfidf_mat_creator(matrixpair[1])\n",
    "    ##print(train_tfidf.shape)\n",
    "    ##print(test_tfidf.shape)\n",
    "    #run do-classify\n",
    "    predictions,accuracy,confusion_matrix,best_param=do_classify(LinearSVC(loss='hinge'), {'C':[1.0]},\n",
    "                                                                 train_tfidf,train_issue_areas,\n",
    "                                                                 test_tfidf,test_issue_areas)\n",
    "    #save results \n",
    "    linear_1_resultsdict[matrixpair[2]]=accuracy\n",
    "for key,value in linear_1_resultsdict.iteritems(): \n",
    "    print key, ': ', value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verbs and adjectives give decent results, and precedents is not terrible. Let's try combining each of these with nouns and seeing what the results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.97\n",
      "Accuracy on test data:     0.69\n",
      "Best parameter:  {'C': 1.0}\n",
      "########################################################\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.97\n",
      "Accuracy on test data:     0.68\n",
      "Best parameter:  {'C': 1.0}\n",
      "########################################################\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.97\n",
      "Accuracy on test data:     0.68\n",
      "Best parameter:  {'C': 1.0}\n",
      "########################################################\n",
      "verbs-nouns :  0.692913385827\n",
      "adj-nouns :  0.681102362205\n",
      "prec-nouns :  0.681102362205\n",
      "CPU times: user 8.03 s, sys: 1.56 s, total: 9.59 s\n",
      "Wall time: 9.51 s\n"
     ]
    }
   ],
   "source": [
    "#EACH OF VERBS, PRECEDENTS, ADJ COMBINED WITH NOUNS \n",
    "%%time\n",
    "nouncomboslist = [[(verb_train_mat,verb_test_mat),(noun_train_mat,noun_test_mat),'verbs-nouns'],\n",
    "                  [(prec_train_mat,prec_test_mat),(noun_train_mat,noun_test_mat),'prec-nouns'],\n",
    "                  [(adj_train_mat,adj_test_mat),(noun_train_mat,noun_test_mat),'adj-nouns']]\n",
    "combosdict={}\n",
    "for combo in nouncomboslist: \n",
    "    #concatenate the nouns matrix and the other matrix \n",
    "    train_combo,test_combo = matrix_combine([combo[0],combo[1]])\n",
    "    #convert to tfidf \n",
    "    train_tfidf = tfidf_mat_creator(train_combo)\n",
    "    test_tfidf = tfidf_mat_creator(test_combo)\n",
    "    #do_classify \n",
    "    predictions,accuracy,confusion_matrix,best_param=do_classify(LinearSVC(loss='hinge'), {'C':[1.0]},train_tfidf,\n",
    "                                                                 train_issue_areas,test_tfidf,test_issue_areas)\n",
    "    #get accuracies in dict \n",
    "    combosdict[combo[2]] = accuracy \n",
    "for key,value in combosdict.iteritems():\n",
    "    print key, ': ', value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.97\n",
      "Accuracy on test data:     0.69\n",
      "Best parameter:  {'C': 1.0}\n",
      "########################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  8.,   8.,   9.,   1.,   9.,   1.,   8.,   9.,   1.,   9.,   7.,\n",
       "          2.,   1.,   7.,  10.,   2.,   8.,   7.,   7.,   8.,  10.,   3.,\n",
       "          2.,   7.,   1.,   9.,   9.,   2.,  10.,   2.,   2.,   2.,   1.,\n",
       "          8.,   8.,   3.,   1.,   8.,   2.,   7.,   8.,   8.,   1.,   1.,\n",
       "          1.,  12.,   8.,   8.,   8.,   2.,   8.,   8.,   8.,   8.,   4.,\n",
       "          3.,   8.,   2.,   8.,   1.,   8.,   2.,   8.,   1.,   7.,   8.,\n",
       "          2.,   3.,   9.,   2.,   8.,   9.,   2.,   1.,   8.,   8.,   1.,\n",
       "          8.,   2.,   8.,   8.,   8.,   8.,   8.,   1.,   9.,   9.,  12.,\n",
       "          8.,  10.,   2.,   1.,   1.,   1.,   3.,   3.,  11.,   1.,   9.,\n",
       "          9.,   8.,   1.,   9.,   3.,   6.,  12.,   9.,   7.,   1.,   8.,\n",
       "          1.,   2.,   7.,   8.,   1.,   7.,   9.,   1.,  11.,   1.,   7.,\n",
       "          8.,   8.,   9.,   3.,   1.,  10.,   8.,  10.,   8.,   2.,   2.,\n",
       "          2.,   8.,   7.,   9.,   9.,   1.,   8.,   3.,   8.,   2.,   1.,\n",
       "          9.,   1.,   2.,   8.,   2.,   1.,   9.,   7.,   3.,   8.,   1.,\n",
       "          9.,   1.,   2.,   8.,   1.,  12.,   8.,   8.,   7.,   7.,   1.,\n",
       "          1.,   2.,   2.,  12.,   1.,   8.,   1.,   1.,   9.,   2.,   2.,\n",
       "          1.,   8.,   1.,   8.,   8.,   8.,   2.,   1.,   1.,   1.,   8.,\n",
       "          1.,   1.,   8.,   3.,   8.,   8.,   2.,   2.,   2.,   8.,   8.,\n",
       "          8.,   1.,   7.,   8.,   8.,   2.,   8.,   3.,   1.,   2.,   1.,\n",
       "          9.,   8.,   2.,   1.,   2.,   1.,  10.,   9.,   1.,   2.,   2.,\n",
       "         10.,   7.,   8.,   1.,   8.,   9.,   2.,   1.,   1.,   2.,   9.,\n",
       "          1.,   8.,   2.,   1.,   8.,   2.,   1.,   2.,   2.,   8.,   8.,\n",
       "          9.,   1.,   1.,   9.,   7.,   1.,  10.,   2.,   2.,   1.,   8.,\n",
       "          8.,   8.,   1.,   9.,   6.,  12.,   8.,   1.,   1.,   2.,   3.,\n",
       "          8.,   9.,   8.,   1.,   7.,   8.,   7.,   9.,   1.,   1.,   2.,\n",
       "          1.,   7.,   3.,   8.,   1.,   1.,   2.,   2.,   1.,   2.,   2.,\n",
       "          1.,   8.,   1.,   1.,   1.,   8.,   9.,   8.,   3.,   7.,   8.,\n",
       "          8.,   8.,   2.,   1.,   1.,   9.,   1.,   8.,   1.,   9.,   3.,\n",
       "          7.,   8.,   2.,   2.,   1.,   8.,   3.,   9.,   8.,   1.,   1.,\n",
       "          1.,  12.,   1.,   8.,   2.,   8.,   8.,   1.,   7.,   8.,   2.,\n",
       "          1.,   3.,   8.,   2.,   2.,   2.,   9.,   1.,   8.,   8.,   1.,\n",
       "          8.,   9.,   2.,   8.,   9.,   2.,   9.,   3.,   8.,  11.,   1.,\n",
       "          1.,   1.,   2.,   1.,   7.,   9.,   1.,   9.,  12.,   1.,   9.,\n",
       "          9.,   2.,   9.,   8.,   7.,   8.,   8.,   8.,   2.,  10.,   9.,\n",
       "          1.,   1.,   1.,   3.,   8.,   8.,   8.,   1.,   8.,   8.,   9.,\n",
       "          3.,   7.,   1.,   8.,   2.,   2.,   1.,   1.,   7.,   2.,   1.,\n",
       "          8.,   3.,   2.,   1.,   2.,   1.,   1.,   2.,   8.,   8.,   1.,\n",
       "          4.,   1.,   1.,   9.,   8.,   3.,   3.,   1.,   8.,   9.,   8.,\n",
       "          2.,   8.,   2.,   2.,   9.,   1.,   2.,   9.,   2.,   9.,   2.,\n",
       "          8.,   7.,   9.,   2.,   8.,   1.,   1.,   8.,   1.,   8.,   2.,\n",
       "         12.,   2.,   8.,   1.,   1.,   1.,   7.,   9.,   2.,   9.,   8.,\n",
       "          1.,   1.,   8.,   9.,   8.,   1.,   1.,   2.,   3.,   8.,   1.,\n",
       "          3.,  12.,   8.,   2.,  12.,   2.,   9.,   8.,   7.,   8.,   8.,\n",
       "          9.,   1.,   7.,   1.,   1.,   8.,   1.,   8.,   8.,   8.,   8.,\n",
       "          7.,   1.,   9.,   7.,   8.,   8.,   8.,   1.,   1.,   1.,   8.,\n",
       "          1.,   9.,   1.,   4.,   8.,   8.,   1.,   3.,   2.,   2.,   3.,\n",
       "          1.,   1.]),\n",
       " 0.69291338582677164,\n",
       " 'confusion_matrix_broken',\n",
       " {'C': 1.0})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VERBS, NOUNS, PRECEDENTS COMBINED \n",
    "verbnounsprec = [(verb_train_mat,verb_test_mat),(noun_train_mat,noun_test_mat),(prec_train_mat,prec_test_mat)]\n",
    "#concatenate \n",
    "vnp_train,vnp_test = matrix_combine(verbnounsprec)\n",
    "#convert to TFIDF\n",
    "vnp_train_tfidf = tfidf_mat_creator(vnp_train)\n",
    "vnp_test_tfidf = tfidf_mat_creator(vnp_test)\n",
    "#run do_classify\n",
    "do_classify(LinearSVC(loss='hinge'), {'C':[1.0]},vnp_train_tfidf,train_issue_areas,vnp_test_tfidf,test_issue_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Visualization ideas (for this and other parts of the project) \n",
    "- Graph of the SVM confusion matrix to show which issue areas were best predicted, and to show overlap between areas. Maybe a 12x12 (or 14x14) heat map showing overlap between columns. For instance, if issue 12 is frequently predicted as issue 10, then the 12-10 (or 10-12) box of the heat map would be dark.\n",
    "- Bar graph comparing the accuracy rating of the best iteration of each model \n",
    "- Show the words that have the greatest influence (e.g., highest absolute coefficients) in each model \n",
    "- Exporatory data analysis: show the most common words; visualize the TF-IDF matrix. Perhaps take the sum of each column (word) of the TF-IDF matrix, as this represents \"overall influence\" of a given word. Then make a plot of these values -- maybe even a visualization that represents importance with word size.  \n",
    "\n",
    "###TO DO: \n",
    "- Keep a dict of all accuracies and models, to select the best one at the end\n",
    "- Explain why we only consider linear after nouns (b/c linear performs essentially as well as kernelized)\n",
    "- Do visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
