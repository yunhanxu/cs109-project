{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option(\"display.width\", 500)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.notebook_repr_html\", True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TF-IDF term weighting \n",
    "TF-IDF (term-frequency inverse document-frequency) is a method for extracting the usefulness of words and terms. It weights up for term frequency in document, and weights down for the number of documents a term appears in. The formula is:  $$\\text{new_frequency} = tf * (idf + 1)$$\n",
    "$tf = \\text{number of times term appears in document}/\\text{number of words in document}$, $idf = \\text{total number of documents}/\\text{number of documents in which term appears}$\n",
    "\n",
    "See: http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting, http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "\n",
    "The below function takes a bag-of-words matrix (size n_documents\\*vocab_size), and outputs the corresponding tfidf matrix. We show an example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample bag-of-words matrix of 3 documents, vocab size 4 words: \n",
      "[[0 3 1 1]\n",
      " [1 4 4 4]\n",
      " [1 2 4 3]]\n",
      "tfidf transformation of above matrix: \n",
      "[[ 0.          0.90453403  0.30151134  0.30151134]\n",
      " [ 0.18273153  0.56762934  0.56762934  0.56762934]\n",
      " [ 0.23256045  0.36120787  0.72241573  0.5418118 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#this function takes a matrix of size n_documents*vocab_size, and outputs the corresponding tfidf matrix \n",
    "def tfidf_mat_creator(wordmatrix):\n",
    "    tf_idf_transform=TfidfTransformer()\n",
    "    return(tf_idf_transform.fit_transform(wordmatrix).toarray())\n",
    "\n",
    "#Example\n",
    "samplematrix = np.random.randint(0, high=5, size=(3,4))\n",
    "print \"Sample bag-of-words matrix of 3 documents, vocab size 4 words: \"\n",
    "print samplematrix\n",
    "print \"tfidf transformation of above matrix: \" \n",
    "print tfidf_mat_creator(samplematrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SVM\n",
    "We try running some SVMs on nouns. \n",
    "\n",
    "First, we must import the noun training and test matrices, and we convert them to tfidf matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GET TRAINING AND TEST MATRICES FOR NOUNS\n",
    "from numpy import genfromtxt\n",
    "##%%time\n",
    "noun_train_df = pd.read_csv('noun_train_mat.csv',sep=',',header=None)\n",
    "noun_train_mat = noun_train_df.values\n",
    "noun_test_df = pd.read_csv('noun_test_mat.csv',sep=',',header=None)\n",
    "noun_test_mat = noun_test_df.values\n",
    "noun_train_issue_areas_df = pd.read_csv('noun_train_issue_areas.csv',sep=',',header=None)\n",
    "noun_train_issue_areas = noun_train_issue_areas_df.values.ravel()\n",
    "noun_test_issue_areas_df = pd.read_csv('noun_test_issue_areas.csv',sep=',',header=None)\n",
    "noun_test_issue_areas = noun_test_issue_areas_df.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert the matrices to tfidf matrices \n",
    "noun_train_tfidf = tfidf_mat_creator(noun_train_mat)\n",
    "noun_test_tfidf = tfidf_mat_creator(noun_test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Simple practice SVM\n",
    "We train and run a simple linear SVM. We follow https://www.quantstart.com/articles/Supervised-Learning-for-Document-Classification-with-Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "##%%time\n",
    "def train_svm(X, y):\n",
    "    #this creates and trains the SVM\n",
    "    svm = SVC(C=1000000.0, gamma=0.0, kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm\n",
    "svm1 = train_svm(noun_train_tfidf,noun_train_issue_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663736263736\n"
     ]
    }
   ],
   "source": [
    "pred = svm1.predict(noun_test_tfidf)\n",
    "#accuracy rate on test set \n",
    "print(svm1.score(noun_test_tfidf, noun_test_issue_areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76 11  7  5  1  0  0  3  5  1  0  0]\n",
      " [ 3 60 10 10  1  1  1  4  9  3  2  1]\n",
      " [ 0  0 19  0  0  0  2  0  1  0  0  0]\n",
      " [ 0  1  0  4  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 22  0  1  3  0  0]\n",
      " [ 1  5  0  4  0  0  2 82  7 10  0  7]\n",
      " [ 1  6  2  1  0  1  1  7 20  2  0  0]\n",
      " [ 0  2  0  1  0  0  0  3  0 10  1  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(pred, noun_test_issue_areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_test_issue_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Trying multiple SVMs\n",
    "We now test a variety of parameters and do cross-validation to optimize the nouns SVM. To do this, we implement functions cv_optimize and do_classify, which are similar to (and largely taken from) the equivalently named functions in problem set 3.\n",
    "\n",
    "####NOTE: SHOULD ALSO TRY THIS WITHOUT DOING TFIDF, TO SHOW WE TRIED MANY POSSIBILITIES. THEN, SHOULD TRY THINGS OTHER THAN NOUNS, AND COMBINATIONS OF WORDS (E.G., NOUNS + PRECEDENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "cv_optimize\n",
    "\n",
    "Inputs\n",
    "------\n",
    "clf : an instance of a scikit-learn classifier\n",
    "parameters: a parameter grid dictionary thats passed to GridSearchCV\n",
    "X: a document-word matrix (e.g., noun_train_tfidf). Should be training data.\n",
    "y: the response vector (e.g., noun_train_issue_areas)\n",
    "n_folds: the number of cross-validation folds (default 5)\n",
    "score_func: a score function we might want to pass (default python None)\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "Two things: (1) The best estimator from the GridSearchCV, after the GridSearchCV has been used to\n",
    "fit the model; and (2) the best parameter. \n",
    "     \n",
    "Notes\n",
    "-----\n",
    "see do_classify below for an example of how this is used\n",
    "\"\"\"\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#note: this code comes directly from lab 6\n",
    "def cv_optimize(clf, parameters, X, y, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "    best_estimator = gs.best_estimator_\n",
    "    best_param = gs.best_params_\n",
    "    return (best_estimator,best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "do_classify\n",
    "\n",
    "Inputs\n",
    "------\n",
    "clf : an instance of a scikit-learn classifier\n",
    "parameters: a parameter grid dictionary thats passed to GridSearchCV\n",
    "Xtrain: a training matrix document-word matrix (e.g., noun_train_tfidf)\n",
    "ytrain: the corresponding training response vector (e.g., noun_train_issue_areas)\n",
    "Xtest: a test matrix document-word matrix (e.g., noun_test_tfidf)\n",
    "ytest: the corresponding test resonse vector (e.g., noun)\n",
    "n_folds: the number of cross-validation folds (default 5)\n",
    "score_func: a score function we might want to pass (default python None)\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "4 things, in the following order: (1) an array of predicted y values (ie, topic areas) for the test data; \n",
    "                                  (2) the accuracy score; (3) the confusion matrix of the test data predictions;\n",
    "                                  (4) the best parameter from the gridsearch.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def do_classify(clf, parameters, Xtrain, ytrain, Xtest, ytest, score_func=None, n_folds=5):\n",
    "    if parameters:\n",
    "        clf,best_param = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    print \"Best parameter: \", best_param\n",
    "    print confusion_matrix(ytest, clf.predict(Xtest))\n",
    "    print \"########################################################\"\n",
    "    return(clf.predict(Xtest),test_accuracy,confusion_matrix(ytest,clf.predict(Xtest)),best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Linear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 3 µs, total: 10 µs\n",
      "Wall time: 14.1 µs\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.97\n",
      "Accuracy on test data:     0.68\n",
      "Best parameter:  {'C': 1.0}\n",
      "[[76  2  0  0  0  0  0  1  2  0  0  0]\n",
      " [10 63  0  0  0  0  1  8  3  1  1  0]\n",
      " [ 9  4 24  0  0  0  0  0  1  0  0  0]\n",
      " [ 9  6  1  1  0  0  1  5  2  0  0  0]\n",
      " [ 1  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 22  3  2  0  0  0]\n",
      " [ 3  3  1  0  0  0  1 86  4  1  0  0]\n",
      " [ 6  3  1  0  0  0  1 11 21  0  0  0]\n",
      " [ 1  1  0  0  0  1  5 11  2  4  4  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  1  2  0]\n",
      " [ 0  0  0  1  0  0  0  9  0  0  0  5]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "#Try do_classify on best 6 parameters\n",
    "%time\n",
    "parameters1 = {\"C\": [0.0001, 0.01, 1.0, 100.0, 1000.0, 100000.0]}\n",
    "predictions1,accuracy1,confusion_matrix1,best_param1=do_classify(LinearSVC(loss='hinge'), parameters1, \n",
    "                                                             noun_train_tfidf,noun_train_issue_areas,\n",
    "                                                             noun_test_tfidf,noun_test_issue_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "Accuracy on training data: 1.00\n",
      "Accuracy on test data:     0.66\n",
      "Best parameter:  {'C': 10.0}\n",
      "[[72  4  0  0  0  0  0  2  3  0  0  0]\n",
      " [10 59  1  0  0  0  1  6  7  2  1  0]\n",
      " [ 6  5 25  0  0  0  0  0  2  0  0  0]\n",
      " [ 6  6  0  5  0  0  1  6  0  1  0  0]\n",
      " [ 1  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  1  0  0  0  0]\n",
      " [ 1  0  2  0  0  0 18  5  2  0  0  0]\n",
      " [ 5  3  0  0  0  0  2 77  6  4  0  2]\n",
      " [ 3  5  1  1  0  0  1 11 21  0  0  0]\n",
      " [ 1  3  0  0  0  1  2  9  1 11  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  1  2  0]\n",
      " [ 0  1  0  1  0  0  0  7  1  0  0  5]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "#Rerun do_classify based on the best parameter above\n",
    "paramvalue = best_param1.values()[0]\n",
    "parameters2 = {\"C\": [paramvalue/10.,paramvalue,paramvalue*10]}\n",
    "predictions2,accuracy2,confusion_matrix2,best_param2=do_classify(LinearSVC(loss='hinge'), parameters2, \n",
    "                                                             noun_train_tfidf,noun_train_issue_areas,\n",
    "                                                             noun_test_tfidf,noun_test_issue_areas)\n",
    "#oddly, the best parameter here is 10.0, even though it gives a worse result than the prior function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Non-linear SVCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 8.82 µs\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.99\n",
      "Accuracy on test data:     0.69\n",
      "Best parameter:  {'C': 100000.0, 'gamma': 1e-05}\n",
      "[[77  2  0  0  0  0  0  1  1  0  0  0]\n",
      " [ 9 63  0  1  0  0  1  5  5  2  1  0]\n",
      " [ 9  3 23  0  0  0  0  2  1  0  0  0]\n",
      " [ 7  6  0  4  0  0  0  6  2  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  1  1  0  0  0]\n",
      " [ 0  0  2  0  0  0 22  3  1  0  0  0]\n",
      " [ 3  1  0  0  0  0  0 88  6  1  0  0]\n",
      " [ 7  3  1  0  0  0  1 11 20  0  0  0]\n",
      " [ 1  2  0  0  0  0  4 11  1  9  1  0]\n",
      " [ 0  1  0  0  0  0  0  1  0  1  1  0]\n",
      " [ 0  0  0  1  0  0  0  8  0  0  0  6]]\n",
      "########################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69230769230769229"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "##%time\n",
    "#parameters grid\n",
    "##parameters3 = {\"C\": [1e-5,1e-3,1,1e3,1e5],\"gamma\":[0,1e-3,1e-5,1e-7]}\n",
    "#test non-linear (kernelized) SVMs\n",
    "##predictions3,accuracy3,confusion_matrix3,best_param3=do_classify(SVC(), parameters3, \n",
    "##                                                             noun_train_tfidf,noun_train_issue_areas,\n",
    "##                                                             noun_test_tfidf,noun_test_issue_areas)\n",
    "accuracy3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Visualization ideas (for this and other parts of the project) \n",
    "- Graph of the SVM confusion matrix to show which issue areas were best predicted, and to show overlap between areas. Maybe a 12x12 (or 14x14) heat map showing overlap between columns. For instance, if issue 12 is frequently predicted as issue 10, then the 12-10 (or 10-12) box of the heat map would be dark.\n",
    "- Bar graph comparing the accuracy rating of the best iteration of each model \n",
    "- Show the words that have the greatest influence (e.g., highest absolute coefficients) in each model \n",
    "- Exporatory data analysis: show the most common words; visualize the TF-IDF matrix. Perhaps take the sum of each column (word) of the TF-IDF matrix, as this represents \"overall influence\" of a given word. Then make a plot of these values -- maybe even a visualization that represents importance with word size.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
